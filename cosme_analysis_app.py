import pandas as pd
import re
import requests
from bs4 import BeautifulSoup
import streamlit as st
import matplotlib.pyplot as plt
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
from textblob import TextBlob
import time

# =====================
# ãƒšãƒ¼ã‚¸è¨­å®š & é«˜ç´šæ„ŸCSS
# =====================
st.set_page_config(page_title="@cosme Review Insight", page_icon="ğŸ’„", layout="wide")

st.markdown(
    """
    <style>
    /* Google Font */
    @import url('https://fonts.googleapis.com/css2?family=Montserrat:wght@400;600&display=swap');

    html, body, [class*="css"]  {
        font-family: 'Montserrat', sans-serif;
    }
    body {
        background: linear-gradient(135deg,#FAF8FF 0%, #FFF 40%);
    }
    h1,h2,h3 {
        color:#7B1FA2;
        font-weight:600;
    }
    .stDownloadButton>button, .stButton>button {
        background:#7B1FA2;
        color:#fff;
        border:none;
        border-radius:8px;
        padding:0.5rem 1.2rem;
        font-weight:600;
        transition:0.3s;
    }
    .stDownloadButton>button:hover, .stButton>button:hover {
        background:#9B4DCC;
    }
    .metric-card {
        background:#ffffff; 
        border-radius:12px; 
        box-shadow:0 4px 14px rgba(0,0,0,0.06);
        padding:1.2rem;
        margin-bottom:1rem;
    }
    </style>
    """, unsafe_allow_html=True)

# =====================
# ã‚µã‚¤ãƒ‰ãƒãƒ¼
# =====================
with st.sidebar:
    st.header("ğŸ” ãƒ¬ãƒ“ãƒ¥ãƒ¼URLã‚’å…¥åŠ›")
    with st.form("url_form"):
        url_input = st.text_input("@cosmeãƒ¬ãƒ“ãƒ¥ãƒ¼URL", placeholder="https://www.cosme.net/products/10240630/review/")
        submitted = st.form_submit_button("åˆ†æã™ã‚‹")
    st.info("â€» URLã¯ /review/ ã§çµ‚ã‚ã‚‹ãƒšãƒ¼ã‚¸ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")

# =====================
# ãƒ¬ãƒ“ãƒ¥ãƒ¼å–å¾—é–¢æ•°ï¼ˆæœ€æ–°ç‰ˆHTMLæ§‹é€ ï¼‰
# =====================

def get_reviews(url:str)->pd.DataFrame:
    headers = {"User-Agent":"Mozilla/5.0"}
    reviews = []
    page = 1
    while True:
        resp = requests.get(f"{url}?page={page}", headers=headers, timeout=10)
        soup = BeautifulSoup(resp.text, "html.parser")
        items = soup.select(".p-reviewList__item")
        if not items:
            break
        for item in items:
            # æ˜Ÿè©•ä¾¡ï¼šæ•´æ•°ã‹å°æ•° ä¾‹ <span class="bl-reviewRating__score">5.3</span>
            score_tag = item.select_one(".bl-reviewRating__score")
            rating = float(score_tag.text) if score_tag else None
            # ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ« ä¾‹: "30ä»£ å¥³æ€§ ä¹¾ç‡¥è‚Œ"
            profile = item.select_one(".p-reviewList__profile").get_text(" ", strip=True)
            # æœ¬æ–‡æŠœç²‹
            excerpt = item.select_one(".p-reviewList__comment").get_text(" ", strip=True)
            # å…¨æ–‡ãƒªãƒ³ã‚¯
            more = item.select_one("a.p-reviewList__moreLink")
            full_txt = excerpt
            if more and more.has_attr("href"):
                time.sleep(0.4)
                det = requests.get(more["href"], headers=headers, timeout=10)
                det_soup = BeautifulSoup(det.text, "html.parser")
                txt_tag = det_soup.select_one(".p-reviewExpand__text")
                if txt_tag:
                    full_txt = txt_tag.get_text(" ", strip=True)
            # æ—¥ä»˜ ä¾‹: 2024/12/01
            date_tag = item.select_one(".p-reviewList__date")
            date = date_tag.text.strip() if date_tag else ""
            reviews.append({"è©•ä¾¡": rating, "å±æ€§": profile, "æœ¬æ–‡": full_txt, "æ—¥ä»˜": date})
        page += 1
    return pd.DataFrame(reviews)

# =====================
# ãƒ¡ã‚¤ãƒ³
# =====================
st.title("ğŸ’„ @cosme Review Insight")
st.caption("å¹´ä»£Ã—è‚Œè³ªã§èª­ã¿è§£ãã‚³ã‚¹ãƒ¡ãƒ¬ãƒ“ãƒ¥ãƒ¼ â”€ æ„Ÿæƒ…åˆ†æ / ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚° / ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ å¯è¦–åŒ–")

if submitted and url_input:
    with st.spinner("ãƒ¬ãƒ“ãƒ¥ãƒ¼å–å¾—ä¸­..."):
        df = get_reviews(url_input)

    if df.empty:
        st.error("ãƒ¬ãƒ“ãƒ¥ãƒ¼ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚URLã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    st.success(f"{len(df)} ä»¶ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’å–å¾—ã—ã¾ã—ãŸï¼")

    # ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«åˆ†è§£
    df[["å¹´ä»£","æ€§åˆ¥","è‚Œè³ª"]] = df["å±æ€§"].str.extract(r"(\d+ä»£)?\s+(ç”·æ€§|å¥³æ€§)?\s+(.*)")

    # -------- ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚«ãƒ¼ãƒ‰ --------
    with st.container():
        col_a, col_b, col_c = st.columns(3)
        col_a.metric("å¹³å‡è©•ä¾¡", f"{df['è©•ä¾¡'].mean():.2f}")
        col_b.metric("ãƒã‚¸ãƒ†ã‚£ãƒ–ç‡", f"{(df['è©•ä¾¡']>=5).mean()*100:.1f}%")
        col_c.metric("ã‚¯ãƒ©ã‚¹ã‚¿æ•°", "3")

    # -------- ã‚°ãƒ©ãƒ•ï¼šå¹´ä»£ & è‚Œè³ª --------
    g1, g2 = st.columns(2)
    with g1:
        st.subheader("ğŸ“Š å¹´ä»£åˆ¥ å¹³å‡è©•ä¾¡")
        fig, ax = plt.subplots()
        df.groupby("å¹´ä»£")["è©•ä¾¡"].mean().plot.bar(color="#9C27B0", edgecolor="black", ax=ax)
        ax.set_ylabel("å¹³å‡è©•ä¾¡"); st.pyplot(fig)
    with g2:
        st.subheader("ğŸ“Š è‚Œè³ªåˆ¥ å¹³å‡è©•ä¾¡")
        fig2, ax2 = plt.subplots()
        df.groupby("è‚Œè³ª")["è©•ä¾¡"].mean().plot.bar(color="#FFB300", edgecolor="black", ax=ax2)
        ax2.set_ylabel("å¹³å‡è©•ä¾¡"); st.pyplot(fig2)

    # -------- æ„Ÿæƒ…ã‚¹ã‚³ã‚¢åˆ†å¸ƒ --------
    st.subheader("ğŸ˜Š æ„Ÿæƒ…ã‚¹ã‚³ã‚¢åˆ†å¸ƒ")
    df["sentiment"] = df["æœ¬æ–‡"].apply(lambda x: TextBlob(x).sentiment.polarity)
    fig3, ax3 = plt.subplots()
    df["sentiment"].hist(bins=30, color="#26A69A", edgecolor="white", ax=ax3)
    ax3.set_xlabel("Polarity"); ax3.set_ylabel("Count")
    st.pyplot(fig3)

    # -------- æ™‚ç³»åˆ—ãƒˆãƒ¬ãƒ³ãƒ‰ --------
    st.subheader("ğŸ“ˆ æ™‚ç³»åˆ— å¹³å‡è©•ä¾¡ãƒˆãƒ¬ãƒ³ãƒ‰")
    df["ãƒ¬ãƒ“ãƒ¥ãƒ¼æ—¥"] = pd.to_datetime(df["æ—¥ä»˜"], errors="coerce")
    trend = df.dropna(subset=["ãƒ¬ãƒ“ãƒ¥ãƒ¼æ—¥"]).groupby("ãƒ¬ãƒ“ãƒ¥ãƒ¼æ—¥")["è©•ä¾¡"].mean()
    fig4, ax4 = plt.subplots()
    trend.plot(ax=ax4, color="#FF7043", marker="o"); ax4.set_ylabel("å¹³å‡è©•ä¾¡")
    st.pyplot(fig4)

    # -------- ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚° --------
    st.subheader("ğŸ‘¥ ãƒ¬ãƒ“ãƒ¥ãƒ¼æœ¬æ–‡ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚° (3-clusters)")
    tfidf = TfidfVectorizer(max_features=50, stop_words="japanese"); X = tfidf.fit_transform(df["æœ¬æ–‡"])
    kmeans = KMeans(n_clusters=3, random_state=42, n_init=10).fit(X)
    df["ã‚¯ãƒ©ã‚¹ã‚¿"] = kmeans.labels_
    st.dataframe(df[["å¹´ä»£","è‚Œè³ª","æ€§åˆ¥","è©•ä¾¡","ã‚¯ãƒ©ã‚¹ã‚¿"]])

    # -------- ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚¯ãƒ­ã‚¹ --------
    st.subheader("ğŸ” å¹´ä»£ Ã— ã‚¯ãƒ©ã‚¹ã‚¿")
    seg = pd.crosstab(df["å¹´ä»£"], df["ã‚¯ãƒ©ã‚¹ã‚¿"])
    st.dataframe(seg.style.background_gradient(cmap="PuRd"))

    # -------- CSV DL --------
    csv = df.to_csv(index=False).encode("utf-8-sig")
    st.download_button("ãƒ‡ãƒ¼ã‚¿CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=csv, file_name="cosme_reviews.csv", mime="text/csv")
