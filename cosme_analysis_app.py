import pandas as pd
import re
import requests
from bs4 import BeautifulSoup
import streamlit as st
import matplotlib.pyplot as plt
# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
plt.rcParams['font.family'] = 'sans-serif'
plt.rcParams['font.sans-serif'] = ['Yu Gothic','Meiryo','TakaoPGothic','Noto Sans CJK JP']
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
from textblob import TextBlob

# ===== Streamlitè¨­å®š =====
st.set_page_config(page_title="@cosme Review Insight", page_icon="ğŸ’„", layout="wide")

# ===== CSS =====
st.markdown(
    """
    <style>
    body { background-color: #FAF8FF; }
    h1, h2, h3 { color: #7B1FA2; font-weight: bold; }
    .stSidebar { background-color: #FFFFFF; padding: 1rem; border-radius: 8px; }
    .stButton>button, .stDownloadButton>button { background-color: #7B1FA2; color: white; border-radius: 8px; }
    </style>
    """, unsafe_allow_html=True)

# ===== ã‚µã‚¤ãƒ‰ãƒãƒ¼ =====
with st.sidebar:
    st.header("ğŸ” ãƒ¬ãƒ“ãƒ¥ãƒ¼åˆ†æè¨­å®š")
    url_input = st.text_input("@cosmeã®å•†å“ãƒšãƒ¼ã‚¸/ãƒ¬ãƒ“ãƒ¥ãƒ¼URLã‚’å…¥åŠ›", placeholder="ä¾‹: https://www.cosme.net/products/10240630/review/")
    max_pages = st.slider("æœ€å¤§ãƒšãƒ¼ã‚¸æ•°", 1, 5, 3)
    submitted = st.button("åˆ†æé–‹å§‹")

# ===== ãƒ¬ãƒ“ãƒ¥ãƒ¼å–å¾— =====
def get_reviews(url: str, max_pages: int) -> pd.DataFrame:
    session = requests.Session()
    session.headers.update({
        "User-Agent": "Mozilla/5.0",
        "Accept-Language": "ja-JP,ja;q=0.9"
    })
    # å•†å“ãƒšãƒ¼ã‚¸URLã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼URLã«å¤‰æ›
    if not url.endswith("/review/"):
        url = url.rstrip("/") + "/review/"

    reviews = []
    for page in range(1, max_pages + 1):
        resp = session.get(f"{url}?page={page}", timeout=10)
        soup = BeautifulSoup(resp.text, "html.parser")
        items = soup.select("#product-review-list > div")
        if not items:
            break
        for item in items:
            # è©•ä¾¡
            score_tag = item.select_one("div.body div.rating.clearfix p.reviewer-rating")
            rating = None
            if score_tag:
                num = re.sub(r"[^0-9.]", "", score_tag.text)
                rating = float(num) if num else None
            # å¹´é½¢ãƒ»è‚Œè³ªãƒ»æ€§åˆ¥: div.tag-list.clearfix li ã«é †ã«å…¥ã£ã¦ã„ã‚‹
            tags = item.select("div.body div.tag-list.clearfix li")
            tag_texts = [t.get_text(strip=True) for t in tags]
            age = tag_texts[0] if len(tag_texts) > 0 else "ä¸æ˜"
            skin = tag_texts[1] if len(tag_texts) > 1 else "ä¸æ˜"
            sex = tag_texts[2] if len(tag_texts) > 2 else "ä¸æ˜"
            # æœ¬æ–‡
            body_tag = item.select_one("div.body p:not(.reviewer-rating):not(.mobile-date)")
            body_txt = body_tag.get_text(strip=True) if body_tag else ""
            # æ—¥ä»˜
            date_tag = item.select_one("div.body div.rating.clearfix p.mobile-date")
            date_txt = date_tag.text.strip() if date_tag else ""
            reviews.append({"è©•ä¾¡": rating, "å¹´é½¢": age, "è‚Œè³ª": skin, "æ€§åˆ¥": sex, "æœ¬æ–‡": body_txt, "æ—¥ä»˜": date_txt})
    return pd.DataFrame(reviews)

# ===== ãƒ¡ã‚¤ãƒ³ =====
st.title("ğŸ’„ @cosme Review Insight")
st.write("è¿…é€Ÿã«ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’å–å¾—ãƒ»åˆ†æã—ã¾ã™ã€‚ãƒšãƒ¼ã‚¸æ•°èª¿æ•´å¯èƒ½ã€‚æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆå¯¾å¿œã€‚")

if submitted and url_input:
    with st.spinner("ãƒ¬ãƒ“ãƒ¥ãƒ¼å–å¾—ä¸­â€¦"):
        df = get_reviews(url_input, max_pages)
    if df.empty:
        st.error("âš ï¸ ãƒ¬ãƒ“ãƒ¥ãƒ¼ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚URLã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    st.success(f"âœ… {len(df)} ä»¶ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’å–å¾—ã—ã¾ã—ãŸï¼")
    # å±æ€§åˆ†è§£ï¼ˆå¹´ä»£ãƒ»æ€§åˆ¥ãƒ»è‚Œè³ªï¼‰
    parts = df['å±æ€§'].str.split(r'[ãƒ»ï¼\s]+', expand=True)
    df['å¹´ä»£'] = parts.iloc[:, 0].fillna('ä¸æ˜')
    df['æ€§åˆ¥'] = parts.iloc[:, 1].fillna('ä¸æ˜')
    df['è‚Œè³ª'] = parts.iloc[:, 2].fillna('ä¸æ˜')

    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹
    c1, c2, c3 = st.columns(3)
    c1.metric("å¹³å‡è©•ä¾¡", f"{df['è©•ä¾¡'].mean():.2f}")
    c2.metric("ãƒã‚¸ãƒ†ã‚£ãƒ–ç‡", f"{(df['è©•ä¾¡']>=5).mean()*100:.1f}%")
    c3.metric("ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°", f"{len(df)}")

    # ã‚°ãƒ©ãƒ•ï¼šå¹´ä»£åˆ¥
    st.subheader("ğŸ“Š å¹´ä»£åˆ¥å¹³å‡è©•ä¾¡")
    fig1, ax1 = plt.subplots()
    df.groupby('å¹´ä»£')['è©•ä¾¡'].mean().plot.bar(ax=ax1)
    ax1.set_xlabel('å¹´ä»£')
    ax1.set_ylabel('å¹³å‡è©•ä¾¡')
    plt.xticks(rotation=45, ha='right')
    st.pyplot(fig1)

    # ã‚°ãƒ©ãƒ•ï¼šæ€§åˆ¥åˆ¥
    st.subheader("ğŸ“Š æ€§åˆ¥åˆ¥å¹³å‡è©•ä¾¡")
    fig2, ax2 = plt.subplots()
    df.groupby('æ€§åˆ¥')['è©•ä¾¡'].mean().plot.bar(ax=ax2)
    ax2.set_xlabel('æ€§åˆ¥')
    ax2.set_ylabel('å¹³å‡è©•ä¾¡')
    plt.xticks(rotation=0)
    st.pyplot(fig2)

    # ã‚°ãƒ©ãƒ•ï¼šè‚Œè³ªåˆ¥
    st.subheader("ğŸ“Š è‚Œè³ªåˆ¥å¹³å‡è©•ä¾¡")
    fig3, ax3 = plt.subplots()
    df.groupby('è‚Œè³ª')['è©•ä¾¡'].mean().plot.bar(ax=ax3)
    ax3.set_xlabel('è‚Œè³ª')
    ax3.set_ylabel('å¹³å‡è©•ä¾¡')
    plt.xticks(rotation=45, ha='right')
    st.pyplot(fig3)

    # æ„Ÿæƒ…ã‚¹ã‚³ã‚¢åˆ†å¸ƒ
    st.subheader("ğŸ˜Š æ„Ÿæƒ…ã‚¹ã‚³ã‚¢åˆ†å¸ƒ")
    df['æ„Ÿæƒ…'] = df['æœ¬æ–‡'].apply(lambda x: TextBlob(x).sentiment.polarity)
    fig4, ax4 = plt.subplots()
    df['æ„Ÿæƒ…'].hist(bins=20, ax=ax4)
    ax4.set_xlabel('æ„Ÿæƒ…ã‚¹ã‚³ã‚¢')
    ax4.set_ylabel('ä»¶æ•°')
    st.pyplot(fig4)

    # ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
    st.subheader("ğŸ‘¥ ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚° (3 clusters)")
    tfidf = TfidfVectorizer(max_features=30)
    X = tfidf.fit_transform(df['æœ¬æ–‡'])
    km = KMeans(n_clusters=3, random_state=42, n_init=10).fit(X)
    df['ã‚¯ãƒ©ã‚¹ã‚¿'] = km.labels_
    st.dataframe(df[['å¹´ä»£','æ€§åˆ¥','è‚Œè³ª','è©•ä¾¡','ã‚¯ãƒ©ã‚¹ã‚¿']])

    # å¹´ä»£Ã—ã‚¯ãƒ©ã‚¹ã‚¿åˆ†å¸ƒ
    st.subheader("ğŸ” å¹´ä»£ Ã— ã‚¯ãƒ©ã‚¹ã‚¿ åˆ†å¸ƒ")
    seg = pd.crosstab(df['å¹´ä»£'], df['ã‚¯ãƒ©ã‚¹ã‚¿'])
    st.dataframe(seg)

    # CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    st.download_button(
        label="CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=df.to_csv(index=False).encode('utf-8-sig'),
        file_name="cosme_reviews.csv",
        mime="text/csv"
    )
