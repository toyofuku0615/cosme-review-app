import pandas as pd
import re
import requests
from bs4 import BeautifulSoup
import streamlit as st
import matplotlib.pyplot as plt
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
from textblob import TextBlob

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
plt.rcParams['font.family'] = 'sans-serif'
plt.rcParams['font.sans-serif'] = ['Yu Gothic', 'Meiryo', 'TakaoPGothic', 'Noto Sans CJK JP']

# Streamlitè¨­å®š
st.set_page_config(page_title="@cosme Review Insight", page_icon="ğŸ’„", layout="wide")

# CSSè£…é£¾
st.markdown("""
<style>
body { background-color: #FAF8FF; }
h1, h2, h3 { color: #7B1FA2; font-weight: bold; }
.stSidebar { background-color: #FFFFFF; padding: 1rem; border-radius: 8px; }
.stButton>button, .stDownloadButton>button { background-color: #7B1FA2; color: white; border-radius: 8px; }
</style>
""", unsafe_allow_html=True)

# ã‚µã‚¤ãƒ‰ãƒãƒ¼å…¥åŠ›
with st.sidebar:
    st.header("ğŸ” ãƒ¬ãƒ“ãƒ¥ãƒ¼åˆ†æè¨­å®š")
    url_input = st.text_input(
        "@cosmeã®å•†å“ãƒšãƒ¼ã‚¸/ãƒ¬ãƒ“ãƒ¥ãƒ¼URLã‚’å…¥åŠ›",
        placeholder="ä¾‹: https://www.cosme.net/products/10240630/review/"
    )
    max_pages = st.slider("æœ€å¤§ãƒšãƒ¼ã‚¸æ•°", 1, 5, 3)
    submitted = st.button("åˆ†æé–‹å§‹")

def get_reviews(url: str, max_pages: int) -> pd.DataFrame:
    session = requests.Session()
    session.headers.update({
        "User-Agent": "Mozilla/5.0",
        "Accept-Language": "ja-JP,ja;q=0.9"
    })

    if not url.endswith("/review/"):
        url = url.rstrip("/") + "/review/"

    reviews = []
    for page in range(1, max_pages + 1):
        resp = session.get(f"{url}?page={page}", timeout=10)
        soup = BeautifulSoup(resp.text, "html.parser")
        items = soup.select("#product-review-list > div")
        if not items:
            break

        for item in items:
            # è©•ä¾¡
            score_tag = item.select_one("div.body div.rating.clearfix p.reviewer-rating")
            rating = None
            if score_tag:
                num = re.sub(r"[^0-9.]", "", score_tag.text)
                rating = float(num) if num else None

            # ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«æƒ…å ±ã®è§£æ (å¹´é½¢ã¨è‚Œè³ª)
            prof_tag = item.select_one("div.head div.reviewer-info")
            prof_txt = prof_tag.get_text(strip=True) if prof_tag else ""
            # å¹´é½¢
            age_match = re.search(r"(\d+)æ­³", prof_txt)
            age = age_match.group(1) + "æ­³" if age_match else "ä¸æ˜"
            # è‚Œè³ª
            skin_match = re.search(r"(ä¹¾ç‡¥è‚Œ|æ··åˆè‚Œ|æ™®é€šè‚Œ)", prof_txt)
            skin = skin_match.group(1) if skin_match else "ä¸æ˜"

            # æœ¬æ–‡
            body_tag = item.select_one("div.body p:not(.reviewer-rating):not(.mobile-date)")
            body_txt = body_tag.get_text(strip=True) if body_tag else ""

            # æ—¥ä»˜
            date_tag = item.select_one("div.body div.rating.clearfix p.mobile-date")
            date_txt = date_tag.text.strip() if date_tag else ""

            reviews.append({
                "è©•ä¾¡": rating,
                "å¹´ä»£": age,
                "è‚Œè³ª": skin,
                "æœ¬æ–‡": body_txt,
                "æ—¥ä»˜": date_txt
            })

    return pd.DataFrame(reviews)

# ãƒ¡ã‚¤ãƒ³ç”»é¢
st.title("ğŸ’„ @cosme Review Insight")
st.write("è¿…é€Ÿã«ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’å–å¾—ãƒ»åˆ†æã—ã¾ã™ã€‚ãƒšãƒ¼ã‚¸æ•°èª¿æ•´å¯èƒ½ã€‚")

if submitted and url_input:
    with st.spinner("ãƒ¬ãƒ“ãƒ¥ãƒ¼å–å¾—ä¸­â€¦"):
        df = get_reviews(url_input, max_pages)
    if df.empty:
        st.error("âš ï¸ ãƒ¬ãƒ“ãƒ¥ãƒ¼ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚URLã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    st.success(f"âœ… {len(df)} ä»¶ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’å–å¾—ã—ã¾ã—ãŸï¼")

    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤º
    c1, c2 = st.columns(2)
    c1.metric("å¹³å‡è©•ä¾¡", f"{df['è©•ä¾¡'].mean():.2f}")
    c2.metric("ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°", f"{len(df)}")

    # å¹´ä»£åˆ¥å¹³å‡è©•ä¾¡
    st.subheader("ğŸ“Š å¹´ä»£åˆ¥å¹³å‡è©•ä¾¡")
    fig1, ax1 = plt.subplots()
    df.groupby('å¹´ä»£')['è©•ä¾¡'].mean().plot.bar(ax=ax1, edgecolor='black')
    ax1.set_xlabel('å¹´ä»£')
    ax1.set_ylabel('å¹³å‡è©•ä¾¡')
    plt.xticks(rotation=45, ha='right')
    st.pyplot(fig1)

    # è‚Œè³ªåˆ¥å¹³å‡è©•ä¾¡
    st.subheader("ğŸ“Š è‚Œè³ªåˆ¥å¹³å‡è©•ä¾¡")
    fig2, ax2 = plt.subplots()
    df.groupby('è‚Œè³ª')['è©•ä¾¡'].mean().plot.bar(ax=ax2, edgecolor='black')
    ax2.set_xlabel('è‚Œè³ª')
    ax2.set_ylabel('å¹³å‡è©•ä¾¡')
    plt.xticks(rotation=45, ha='right')
    st.pyplot(fig2)

    # æ„Ÿæƒ…ã‚¹ã‚³ã‚¢åˆ†å¸ƒ
    st.subheader("ğŸ˜Š æ„Ÿæƒ…ã‚¹ã‚³ã‚¢åˆ†å¸ƒ")
    df['æ„Ÿæƒ…'] = df['æœ¬æ–‡'].apply(lambda x: TextBlob(x).sentiment.polarity)
    fig3, ax3 = plt.subplots()
    df['æ„Ÿæƒ…'].hist(bins=20, ax=ax3)
    ax3.set_xlabel('æ„Ÿæƒ…ã‚¹ã‚³ã‚¢')
    ax3.set_ylabel('ä»¶æ•°')
    st.pyplot(fig3)

    # ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
    st.subheader("ğŸ‘¥ ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚° (3 clusters)")
    tfidf = TfidfVectorizer(max_features=30)
    X = tfidf.fit_transform(df['æœ¬æ–‡'])
    km = KMeans(n_clusters=3, random_state=42, n_init=10).fit(X)
    df['ã‚¯ãƒ©ã‚¹ã‚¿'] = km.labels_
    st.dataframe(df[['å¹´ä»£','è‚Œè³ª','è©•ä¾¡','ã‚¯ãƒ©ã‚¹ã‚¿']])

    # å¹´ä»£ Ã— ã‚¯ãƒ©ã‚¹ã‚¿åˆ†å¸ƒ
    st.subheader("ğŸ” å¹´ä»£ Ã— ã‚¯ãƒ©ã‚¹ã‚¿ åˆ†å¸ƒ")
    seg = pd.crosstab(df['å¹´ä»£'], df['ã‚¯ãƒ©ã‚¹ã‚¿'])
    st.dataframe(seg)

    # CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    st.download_button(
        label="CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=df.to_csv(index=False).encode('utf-8-sig'),
        file_name="cosme_reviews.csv",
        mime="text/csv"
    )
