import pandas as pd
import re
import requests
from bs4 import BeautifulSoup
import streamlit as st
import matplotlib.pyplot as plt
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
from textblob import TextBlob
import time

# =====================
# ãƒšãƒ¼ã‚¸è¨­å®š & ãƒã‚¤ã‚¯ãƒ©ã‚¹CSS
# =====================
st.set_page_config(page_title="@cosme Review Insight", page_icon="ğŸ’„", layout="wide")
st.markdown(
    """
    <style>
    @import url('https://fonts.googleapis.com/css2?family=Montserrat:wght@400;600&display=swap');
    html, body, [class*="css"] { font-family: 'Montserrat', sans-serif; }
    body { background: linear-gradient(135deg, #FAF8FF 0%, #FFF 40%); }
    h1,h2,h3 { color:#7B1FA2; font-weight:600; }
    .stButton>button, .stDownloadButton>button {
        background:#7B1FA2; color:#fff; border:none; border-radius:8px;
        padding:0.5rem 1.2rem; font-weight:600; transition:0.3s;
    }
    .stButton>button:hover, .stDownloadButton>button:hover { background:#9B4DCC; }
    .metric-card {
        background:#fff; border-radius:12px; box-shadow:0 4px 14px rgba(0,0,0,0.06);
        padding:1rem; margin:0.5rem 0;
    }
    </style>
    """, unsafe_allow_html=True)

# =====================
# ã‚µã‚¤ãƒ‰ãƒãƒ¼
# =====================
with st.sidebar:
    st.header("ğŸ” ãƒ¬ãƒ“ãƒ¥ãƒ¼URLã‚’å…¥åŠ›")
    with st.form("sidebar_form"):
        url_input = st.text_input("@cosmeãƒ¬ãƒ“ãƒ¥ãƒ¼URL", placeholder="ä¾‹: https://www.cosme.net/products/10240630/review/")
        submitted = st.form_submit_button("åˆ†æã™ã‚‹")
    st.info("â€» URLã¯ /review/ ã§çµ‚ã‚ã‚‹ãƒšãƒ¼ã‚¸ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")

# =====================
# ãƒ¬ãƒ“ãƒ¥ãƒ¼å–å¾—é–¢æ•°ï¼ˆæœ€æ–°HTMLæ§‹é€ å¯¾å¿œï¼‰
# =====================
def get_reviews(url: str) -> pd.DataFrame:
    headers = {"User-Agent": "Mozilla/5.0"}
    reviews = []
    page = 1
    while True:
        resp = requests.get(f"{url}?page={page}", headers=headers, timeout=10)
        soup = BeautifulSoup(resp.text, "html.parser")
        items = soup.select(".p-reviewList__item")
        if not items:
            break
        for item in items:
            # è©•ä¾¡ã‚¹ã‚³ã‚¢ï¼ˆå°æ•°å¯¾å¿œï¼‰
            score_tag = item.select_one(".bl-reviewRating__score")
            rating = float(score_tag.text) if score_tag else None
            # ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«
            prof_tag = item.select_one(".p-reviewList__profile")
            profile_txt = prof_tag.get_text(" ", strip=True) if prof_tag else ""
            # æŠœç²‹ãƒ†ã‚­ã‚¹ãƒˆ
            excerpt_tag = item.select_one(".p-reviewList__comment")
            excerpt = excerpt_tag.get_text(" ", strip=True) if excerpt_tag else ""
            # ã€ç¶šãã‚’èª­ã‚€ã€ãƒªãƒ³ã‚¯ã§å…¨æ–‡å–å¾—
            more = item.select_one("a.p-reviewList__moreLink")
            full_txt = excerpt
            if more and more.has_attr("href"):
                time.sleep(0.3)
                det = requests.get(more['href'], headers=headers, timeout=10)
                det_soup = BeautifulSoup(det.text, "html.parser")
                txt_tag = det_soup.select_one(".p-reviewExpand__text")
                if txt_tag:
                    full_txt = txt_tag.get_text(" ", strip=True)
            # æ—¥ä»˜
            date_tag = item.select_one(".p-reviewList__date")
            date_txt = date_tag.text.strip() if date_tag else ""
            reviews.append({
                "è©•ä¾¡": rating,
                "å±æ€§": profile_txt,
                "æœ¬æ–‡": full_txt,
                "æ—¥ä»˜": date_txt
            })
        page += 1
    return pd.DataFrame(reviews)

# =====================
# ãƒ¡ã‚¤ãƒ³è¡¨ç¤º
# =====================
st.title("ğŸ’„ @cosme Review Insight")
st.caption("å¹´ä»£Ã—è‚Œè³ªã§èª­ã¿è§£ãã‚³ã‚¹ãƒ¡ãƒ¬ãƒ“ãƒ¥ãƒ¼ â”€ æ„Ÿæƒ…åˆ†æãƒ»ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ãƒ»ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ†æ")

if submitted and url_input:
    with st.spinner("ãƒ¬ãƒ“ãƒ¥ãƒ¼å–å¾—ä¸­â€¦"):
        df = get_reviews(url_input)
    if df.empty:
        st.error("âš ï¸ ãƒ¬ãƒ“ãƒ¥ãƒ¼ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚URLã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    else:
        st.success(f"âœ… {len(df)} ä»¶ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’å–å¾—ã—ã¾ã—ãŸï¼")
        # ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«åˆ†è§£
        df[["å¹´ä»£","æ€§åˆ¥","è‚Œè³ª"]] = df["å±æ€§"].str.extract(r"(\d+ä»£)\s+(ç”·æ€§|å¥³æ€§)\s+(.*)")
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚«ãƒ¼ãƒ‰
        col1, col2, col3 = st.columns(3)
        with col1:
            st.markdown("""<div class='metric-card'><h3>å¹³å‡è©•ä¾¡</h3><p><strong>{:.2f}</strong></p></div>""".format(df['è©•ä¾¡'].mean()), unsafe_allow_html=True)
        with col2:
            pos_rate = (df['è©•ä¾¡'] >= 5).mean() * 100
            st.markdown("""<div class='metric-card'><h3>ãƒã‚¸ãƒ†ã‚£ãƒ–ç‡</h3><p><strong>{:.1f}%</strong></p></div>""".format(pos_rate), unsafe_allow_html=True)
        with col3:
            st.markdown("""<div class='metric-card'><h3>ã‚¯ãƒ©ã‚¹ã‚¿æ•°</h3><p><strong>3</strong></p></div>""", unsafe_allow_html=True)
        # ã‚°ãƒ©ãƒ•è¡¨ç¤º
        g1, g2 = st.columns(2)
        with g1:
            st.subheader("å¹´ä»£åˆ¥å¹³å‡è©•ä¾¡")
            fig, ax = plt.subplots()
            df.groupby("å¹´ä»£")["è©•ä¾¡"].mean().plot.bar(color="#9C27B0", edgecolor="black", ax=ax)
            ax.set_ylabel("å¹³å‡è©•ä¾¡")
            st.pyplot(fig)
        with g2:
            st.subheader("è‚Œè³ªåˆ¥å¹³å‡è©•ä¾¡")
            fig2, ax2 = plt.subplots()
            df.groupby("è‚Œè³ª")["è©•ä¾¡"].mean().plot.bar(color="#FFB300", edgecolor="black", ax=ax2)
            ax2.set_ylabel("å¹³å‡è©•ä¾¡")
            st.pyplot(fig2)
        # æ„Ÿæƒ…ã‚¹ã‚³ã‚¢åˆ†å¸ƒ
        st.subheader("æ„Ÿæƒ…ã‚¹ã‚³ã‚¢åˆ†å¸ƒ")
        df['sentiment'] = df['æœ¬æ–‡'].apply(lambda x: TextBlob(x).sentiment.polarity)
        fig3, ax3 = plt.subplots()
        df['sentiment'].hist(bins=30, color="#26A69A", edgecolor="white", ax=ax3)
        ax3.set_xlabel("Polarity")
        ax3.set_ylabel("ä»¶æ•°")
        st.pyplot(fig3)
        # æ™‚ç³»åˆ—ãƒˆãƒ¬ãƒ³ãƒ‰
        st.subheader("è©•ä¾¡ã®æ™‚ç³»åˆ—ãƒˆãƒ¬ãƒ³ãƒ‰")
        df['ãƒ¬ãƒ“ãƒ¥ãƒ¼æ—¥'] = pd.to_datetime(df['æ—¥ä»˜'], errors='coerce')
        trend = df.dropna(subset=['ãƒ¬ãƒ“ãƒ¥ãƒ¼æ—¥']).groupby('ãƒ¬ãƒ“ãƒ¥ãƒ¼æ—¥')['è©•ä¾¡'].mean()
        fig4, ax4 = plt.subplots()
        trend.plot(marker='o', color="#FF7043", ax=ax4)
        ax4.set_ylabel("å¹³å‡è©•ä¾¡")
        st.pyplot(fig4)
        # ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
        st.subheader("ãƒ¬ãƒ“ãƒ¥ãƒ¼æœ¬æ–‡ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚° (3 clusters)")
        tfidf = TfidfVectorizer(max_features=50, stop_words="japanese")
        X = tfidf.fit_transform(df['æœ¬æ–‡'])
        kmeans = KMeans(n_clusters=3, random_state=42, n_init=10).fit(X)
        df['ã‚¯ãƒ©ã‚¹ã‚¿'] = kmeans.labels_
        st.dataframe(df[['å¹´ä»£','æ€§åˆ¥','è‚Œè³ª','è©•ä¾¡','ã‚¯ãƒ©ã‚¹ã‚¿']])
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ
        st.subheader("å¹´ä»£ Ã— ã‚¯ãƒ©ã‚¹ã‚¿ åˆ†å¸ƒ")
        seg = pd.crosstab(df['å¹´ä»£'], df['ã‚¯ãƒ©ã‚¹ã‚¿'])
        st.dataframe(seg.style.background_gradient(cmap='PuRd'))
        # CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        csv = df.to_csv(index=False).encode('utf-8-sig')
        st.download_button("CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=csv, file_name="cosme_reviews.csv", mime="text/csv")
