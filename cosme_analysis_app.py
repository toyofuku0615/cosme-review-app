import pandas as pd
import requests
from bs4 import BeautifulSoup
import streamlit as st
import matplotlib.pyplot as plt
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
from textblob import TextBlob
import datetime

st.set_page_config(page_title="@cosmeãƒ¬ãƒ“ãƒ¥ãƒ¼åˆ†æã‚¢ãƒ—ãƒª", layout="wide")
st.title("ğŸ’„ @cosmeãƒ¬ãƒ“ãƒ¥ãƒ¼åˆ†æã‚µã‚¤ãƒˆ")
st.markdown("""
ã“ã®ã‚µã‚¤ãƒˆã§ã¯ã€@cosmeã®ãƒ¬ãƒ“ãƒ¥ãƒ¼URLã‚’å…¥åŠ›ã™ã‚‹ã“ã¨ã§ã€
å¹´ä»£åˆ¥ãƒ»è‚Œè³ªåˆ¥ã®è©•ä¾¡å‚¾å‘ã‚„ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®ç‰¹å¾´èªã€æ„Ÿæƒ…å‚¾å‘ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¯ãƒ©ã‚¹ã‚¿ã‚’è‡ªå‹•çš„ã«åˆ†æã—ã¾ã™ã€‚
""")

with st.form("url_form"):
    url_input = st.text_input("@cosmeã®ãƒ¬ãƒ“ãƒ¥ãƒ¼URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", placeholder="ä¾‹: https://www.cosme.net/product/product_id/10104342/review")
    submitted = st.form_submit_button("æ¤œç´¢")

def get_reviews(url):
    headers = {"User-Agent": "Mozilla/5.0"}
    res = requests.get(url, headers=headers)
    soup = BeautifulSoup(res.text, "html.parser")
    reviews = []

    for block in soup.select(".review__item"):
        rating = block.select_one(".review__rating")
        profile = block.select_one(".review__profile")
        text = block.select_one(".review__body")
        date = block.select_one(".review__date")

        reviews.append({
            "è©•ä¾¡": int(rating.get_text(strip=True)[0]) if rating else None,
            "å±æ€§": profile.get_text(strip=True) if profile else "",
            "æœ¬æ–‡": text.get_text(strip=True) if text else "",
            "æ—¥ä»˜": date.get_text(strip=True) if date else ""
        })
    return pd.DataFrame(reviews)

if submitted and url_input:
    try:
        df = get_reviews(url_input)
        st.success(f"âœ… {len(df)} ä»¶ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’å–å¾—ã—ã¾ã—ãŸ")

        df[["å¹´ä»£", "è‚Œè³ª", "æ€§åˆ¥"]] = df["å±æ€§"].str.extract(r"(\\d+ä»£)?ãƒ»(.*?)ãƒ»(.*?)$")

        st.subheader("ğŸ˜Š æ„Ÿæƒ…åˆ†æï¼ˆãƒã‚¸ãƒ†ã‚£ãƒ–/ãƒã‚¬ãƒ†ã‚£ãƒ–ï¼‰")
        df["æ„Ÿæƒ…ã‚¹ã‚³ã‚¢"] = df["æœ¬æ–‡"].apply(lambda x: TextBlob(x).sentiment.polarity if x else 0)
        fig3, ax3 = plt.subplots()
        df["æ„Ÿæƒ…ã‚¹ã‚³ã‚¢"].hist(bins=20, ax=ax3)
        ax3.set_title("æ„Ÿæƒ…ã‚¹ã‚³ã‚¢ã®åˆ†å¸ƒ")
        st.pyplot(fig3)

        if df["æ—¥ä»˜"].notna().all():
            try:
                df["ãƒ¬ãƒ“ãƒ¥ãƒ¼æ—¥"] = pd.to_datetime(df["æ—¥ä»˜"], errors='coerce')
                df_sorted = df.sort_values("ãƒ¬ãƒ“ãƒ¥ãƒ¼æ—¥")
                df_trend = df_sorted.groupby("ãƒ¬ãƒ“ãƒ¥ãƒ¼æ—¥")["è©•ä¾¡"].mean()

                st.subheader("ğŸ“ˆ è©•ä¾¡ã®æ™‚ç³»åˆ—ãƒˆãƒ¬ãƒ³ãƒ‰")
                fig4, ax4 = plt.subplots()
                df_trend.plot(ax=ax4)
                ax4.set_ylabel("å¹³å‡è©•ä¾¡")
                st.pyplot(fig4)
            except:
                st.warning("ãƒ¬ãƒ“ãƒ¥ãƒ¼æ—¥ãŒé©åˆ‡ã«å–å¾—ã§ããªã‹ã£ãŸãŸã‚ã€æ™‚ç³»åˆ—ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’è¡¨ç¤ºã§ãã¾ã›ã‚“")

        st.subheader("ğŸ‘¥ å±æ€§åˆ¥ãƒ¬ãƒ“ãƒ¥ãƒ¼å†…å®¹ã®ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°")
        tfidf_vec = TfidfVectorizer(max_features=50, stop_words="japanese")
        tfidf_matrix = tfidf_vec.fit_transform(df["æœ¬æ–‡"].fillna(""))
        kmeans = KMeans(n_clusters=3, random_state=0, n_init=10).fit(tfidf_matrix)
        df["ã‚¯ãƒ©ã‚¹ã‚¿"] = kmeans.labels_
        st.dataframe(df[["å¹´ä»£", "è‚Œè³ª", "æ€§åˆ¥", "è©•ä¾¡", "ã‚¯ãƒ©ã‚¹ã‚¿"]])

        st.subheader("ğŸ” ãƒ¦ãƒ¼ã‚¶ãƒ¼ã”ã¨ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆï¼ˆå¹´ä»£Ã—ã‚¯ãƒ©ã‚¹ã‚¿ï¼‰")
        seg_table = pd.crosstab(df["å¹´ä»£"], df["ã‚¯ãƒ©ã‚¹ã‚¿"])
        st.dataframe(seg_table)

    except Exception as e:
        st.error(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸï¼š{e}")
