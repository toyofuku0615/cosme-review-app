import pandas as pd
import re
import requests
from bs4 import BeautifulSoup
import streamlit as st
import matplotlib.pyplot as plt
# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
plt.rcParams['font.family'] = 'sans-serif'
plt.rcParams['font.sans-serif'] = ['Yu Gothic','Meiryo','TakaoPGothic','Noto Sans CJK JP']
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
from textblob import TextBlob

# ===== Streamlit ãƒšãƒ¼ã‚¸è¨­å®š & CSS =====
st.set_page_config(page_title="@cosme Review Insight", page_icon="ğŸ’„", layout="wide")
st.markdown(
    """
    <style>
    @import url('https://fonts.googleapis.com/css2?family=Montserrat:wght@400;600&display=swap');
    html, body, [class*="css"] { font-family: 'Montserrat', sans-serif; }
    body { background: #FAF8FF; padding:1rem; }
    h1,h2,h3 { color:#7B1FA2; font-weight:600; }
    .stButton>button, .stDownloadButton>button { background:#7B1FA2; color:#fff; border:none; border-radius:8px; padding:0.5rem 1.2rem; font-weight:600; }
    .stButton>button:hover, .stDownloadButton>button:hover { background:#9B4DCC; }
    </style>
    """, unsafe_allow_html=True)

# ===== ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š =====
with st.sidebar:
    st.header("ğŸ” ãƒ¬ãƒ“ãƒ¥ãƒ¼åˆ†æè¨­å®š")
    url_input = st.text_input("@cosmeãƒ¬ãƒ“ãƒ¥ãƒ¼URL", placeholder="https://www.cosme.net/products/10240630/review/")
    max_pages = st.slider("æœ€å¤§ãƒšãƒ¼ã‚¸æ•°", 1, 5, 2)
    submitted = st.button("åˆ†æé–‹å§‹")
    st.info("â€» URLã¯ /review/ ã§çµ‚ã‚ã‚‹ãƒšãƒ¼ã‚¸ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")

# ===== ãƒ¬ãƒ“ãƒ¥ãƒ¼å–å¾—é–¢æ•° =====
def get_reviews(url: str, max_pages: int) -> pd.DataFrame:
    session = requests.Session()
    session.headers.update({
        "User-Agent": "Mozilla/5.0",
        "Accept-Language": "ja-JP,ja;q=0.9"
    })
    reviews = []
    for page in range(1, max_pages + 1):
        resp = session.get(f"{url}?page={page}", timeout=10)
        soup = BeautifulSoup(resp.text, "html.parser")
        items = soup.select("#product-review-list > div")
        if not items:
            break
        for item in items:
            star = item.select_one("div.body div.rating.clearfix p.reviewer-rating")
            rating = float(re.sub(r"[^0-9.]", "", star.text)) if star else None
            prof = item.select_one("div.head div.reviewer-info")
            profile = prof.get_text(" ", strip=True) if prof else ""
            body = item.select_one("div.body > p:not(.reviewer-rating):not(.mobile-date)")
            text = body.get_text(strip=True) if body else ""
            date = item.select_one("div.body div.rating.clearfix p.mobile-date")
            date_txt = date.get_text(strip=True) if date else ""
            reviews.append({"è©•ä¾¡": rating, "å±æ€§": profile, "æœ¬æ–‡": text, "æ—¥ä»˜": date_txt})
    return pd.DataFrame(reviews)

# ===== ãƒ¡ã‚¤ãƒ³ =====
st.title("ğŸ’„ @cosme Review Insight")
st.caption("è¿…é€Ÿã«ã‚³ã‚¹ãƒ¡ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’å–å¾—ãƒ»åˆ†æã—ã¾ã™ã€‚æœ€å¤§ãƒšãƒ¼ã‚¸æ•°ã§é€Ÿåº¦èª¿æ•´å¯èƒ½ã€‚æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆå¯¾å¿œæ¸ˆã¿ã€‚")

if submitted and url_input:
    with st.spinner("ãƒ¬ãƒ“ãƒ¥ãƒ¼å–å¾—ä¸­â€¦"):
        df = get_reviews(url_input, max_pages)

    if df.empty:
        st.error("âš ï¸ ãƒ¬ãƒ“ãƒ¥ãƒ¼ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚URLã¾ãŸã¯ãƒšãƒ¼ã‚¸æ•°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    else:
        st.success(f"âœ… {len(df)} ä»¶ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’å–å¾—ã—ã¾ã—ãŸï¼")
        # å±æ€§åˆ†è§£ï¼šå¹´é½¢ãƒ»æ€§åˆ¥ãƒ»è‚Œè³ªã‚’æŠ½å‡º
        df['å¹´é½¢'] = df['å±æ€§'].str.extract(r"(\d+)æ­³")[0].fillna('ä¸æ˜').apply(lambda x: x+'æ­³' if x!='ä¸æ˜' else x)
        df['æ€§åˆ¥'] = df['å±æ€§'].str.extract(r"(ç”·æ€§|å¥³æ€§)")[0].fillna('ä¸æ˜')
        df['è‚Œè³ª'] = df['å±æ€§'].str.extract(r"(ä¹¾ç‡¥è‚Œ|è„‚æ€§è‚Œ|æ™®é€šè‚Œ|æ··åˆè‚Œ)")[0].fillna('ä¸æ˜')

        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚«ãƒ¼ãƒ‰
        c1, c2, c3 = st.columns(3)
        c1.metric("å¹³å‡è©•ä¾¡", f"{df['è©•ä¾¡'].mean():.2f}")
        c2.metric("ãƒã‚¸ãƒ†ã‚£ãƒ–ç‡", f"{(df['è©•ä¾¡']>=5).mean()*100:.1f}%")
        c3.metric("ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°", f"{len(df)} ä»¶")

        # å¹´ä»£åˆ¥/è‚Œè³ªåˆ¥è©•ä¾¡ã‚°ãƒ©ãƒ•
        g1, g2 = st.columns(2)
        with g1:
            st.subheader("å¹´ä»£åˆ¥å¹³å‡è©•ä¾¡")
            fig, ax = plt.subplots()
            df.groupby("å¹´é½¢")["è©•ä¾¡"].mean().plot.bar(ax=ax, edgecolor="black")
            ax.set_ylabel("å¹³å‡è©•ä¾¡")
            st.pyplot(fig)
        with g2:
            st.subheader("è‚Œè³ªåˆ¥å¹³å‡è©•ä¾¡")
            fig2, ax2 = plt.subplots()
            df.groupby("è‚Œè³ª")["è©•ä¾¡"].mean().plot.bar(ax=ax2, edgecolor="black")
            ax2.set_ylabel("å¹³å‡è©•ä¾¡")
            st.pyplot(fig2)

        # æ„Ÿæƒ…ã‚¹ã‚³ã‚¢åˆ†å¸ƒ
        st.subheader("æ„Ÿæƒ…ã‚¹ã‚³ã‚¢åˆ†å¸ƒ")
        df['sentiment'] = df['æœ¬æ–‡'].apply(lambda x: TextBlob(x).sentiment.polarity)
        fig3, ax3 = plt.subplots()
        df['sentiment'].hist(bins=20, color="#26A69A", edgecolor="white", ax=ax3)
        ax3.set_xlabel("Polarity")
        ax3.set_ylabel("ä»¶æ•°")
        st.pyplot(fig3)

        # ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
        st.subheader("ãƒ¬ãƒ“ãƒ¥ãƒ¼æœ¬æ–‡ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚° (3 clusters)")
        tfidf = TfidfVectorizer(max_features=30)
        X = tfidf.fit_transform(df['æœ¬æ–‡'])
        km = KMeans(n_clusters=3, random_state=42, n_init=10).fit(X)
        df['ã‚¯ãƒ©ã‚¹ã‚¿'] = km.labels_
        st.dataframe(df[['å¹´é½¢','æ€§åˆ¥','è‚Œè³ª','è©•ä¾¡','ã‚¯ãƒ©ã‚¹ã‚¿']])

        # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ†å¸ƒ
        st.subheader("å¹´ä»£Ã—ã‚¯ãƒ©ã‚¹ã‚¿ åˆ†å¸ƒ")
        seg = pd.crosstab(df['å¹´é½¢'], df['ã‚¯ãƒ©ã‚¹ã‚¿'])
        st.dataframe(seg)

        # CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        csv = df.to_csv(index=False).encode('utf-8-sig')
        st.download_button("CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=csv, file_name="cosme_reviews.csv", mime="text/csv")
