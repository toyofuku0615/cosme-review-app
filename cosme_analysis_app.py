import pandas as pd
import re
import requests
from bs4 import BeautifulSoup
import streamlit as st
import matplotlib.pyplot as plt
import japanize_matplotlib
japanize_matplotlib.japanize()
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
from textblob import TextBlob

# ===== Streamlitãƒšãƒ¼ã‚¸è¨­å®š =====
st.set_page_config(page_title="@cosme Review Insight", page_icon="ğŸ’„", layout="wide")

# ===== ã‚«ã‚¹ã‚¿ãƒ CSS =====
st.markdown(
    """
    <style>
    body { background-color: #FAF8FF; }
    h1, h2, h3 { color: #7B1FA2; font-weight: bold; }
    .stSidebar { background-color: #FFFFFF; padding: 1rem; border-radius: 8px; }
    .stButton>button, .stDownloadButton>button { background-color: #7B1FA2; color: white; border-radius: 8px; }
    </style>
    """, unsafe_allow_html=True)

# ===== ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š =====
with st.sidebar:
    st.header("ğŸ” ãƒ¬ãƒ“ãƒ¥ãƒ¼åˆ†æè¨­å®š")
    url_input = st.text_input("@cosmeã®å•†å“ãƒšãƒ¼ã‚¸/ãƒ¬ãƒ“ãƒ¥ãƒ¼URLã‚’å…¥åŠ›", placeholder="ä¾‹: https://www.cosme.net/products/10240630/review/")
    submitted = st.button("åˆ†æé–‹å§‹")

# ===== ãƒ¬ãƒ“ãƒ¥ãƒ¼å–å¾—é–¢æ•° =====
def get_reviews(url: str, max_pages: int = 3) -> pd.DataFrame:
    session = requests.Session()
    session.headers.update({"User-Agent": "Mozilla/5.0", "Accept-Language": "ja-JP,ja;q=0.9"})
    # å•†å“ãƒšãƒ¼ã‚¸ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼URLã«å¤‰æ›
    if not url.endswith("/review/"):
        url = url.rstrip("/") + "/review/"
    reviews = []
    for page in range(1, max_pages + 1):
        resp = session.get(f"{url}?page={page}", timeout=10)
        soup = BeautifulSoup(resp.text, "html.parser")
        items = soup.select("#product-review-list > div")
        if not items:
            break
        for item in items:
            # è©•ä¾¡
            score_tag = item.select_one("div.body div.rating.clearfix p.reviewer-rating")
            rating = float(re.sub(r"[^0-9.]", "", score_tag.text)) if score_tag else None
            # å±æ€§ï¼ˆå¹´ä»£ æ€§åˆ¥ è‚Œè³ªï¼‰
            info_tag = item.select_one("div.head div.reviewer-info")
            profile_txt = info_tag.get_text(" ", strip=True) if info_tag else ""
            # æœ¬æ–‡
            body_tag = item.select_one("div.body p:not(.reviewer-rating):not(.mobile-date)")
            body_txt = body_tag.get_text(strip=True) if body_tag else ""
            # æŠ•ç¨¿æ—¥
            date_tag = item.select_one("div.body div.rating.clearfix p.mobile-date")
            date_txt = date_tag.text.strip() if date_tag else ""
            reviews.append({"è©•ä¾¡": rating, "å±æ€§": profile_txt, "æœ¬æ–‡": body_txt, "æ—¥ä»˜": date_txt})
    return pd.DataFrame(reviews)

# ===== ãƒ¡ã‚¤ãƒ³å‡¦ç† =====
st.title("ğŸ’„ @cosme Review Insight")
st.write("è¿…é€Ÿã«ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’å–å¾—ãƒ»åˆ†æã—ã¾ã™ã€‚æ—¥æœ¬èªã‚°ãƒ©ãƒ•å¯¾å¿œæ¸ˆã¿ã€‚æœ€å¤§3ãƒšãƒ¼ã‚¸ã¾ã§è¨­å®šå¯èƒ½ã€‚")

if submitted and url_input:
    with st.spinner("ãƒ¬ãƒ“ãƒ¥ãƒ¼å–å¾—ä¸­â€¦"):
        df = get_reviews(url_input)
    if df.empty:
        st.error("âš ï¸ ãƒ¬ãƒ“ãƒ¥ãƒ¼ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚URLã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    # æˆåŠŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    st.success(f"âœ… {len(df)} ä»¶ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’å–å¾—ã—ã¾ã—ãŸï¼")

    # å±æ€§åˆ†è§£ï¼šå¹´ä»£ã€æ€§åˆ¥ã€è‚Œè³ª (ãƒ»åŒºåˆ‡ã‚Š)
    parts = df['å±æ€§'].str.split('ãƒ»', expand=True)
    df['å¹´ä»£'] = parts[0].fillna('ä¸æ˜')
    df['æ€§åˆ¥'] = parts[1].fillna('ä¸æ˜')
    df['è‚Œè³ª'] = parts[2].fillna('ä¸æ˜')

    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤º
    col1, col2, col3 = st.columns(3)
    col1.metric("å¹³å‡è©•ä¾¡", f"{df['è©•ä¾¡'].mean():.2f}")
    col2.metric("ãƒã‚¸ãƒ†ã‚£ãƒ–ç‡", f"{(df['è©•ä¾¡'] >= 5).mean() * 100:.1f}%")
    col3.metric("ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°", f"{len(df)}")

    # ã‚°ãƒ©ãƒ•ï¼šå¹´ä»£åˆ¥å¹³å‡è©•ä¾¡
    st.subheader("ğŸ“Š å¹´ä»£åˆ¥å¹³å‡è©•ä¾¡")
    fig1, ax1 = plt.subplots()
    df.groupby('å¹´ä»£')['è©•ä¾¡'].mean().plot.bar(ax=ax1)
    ax1.set_xlabel('å¹´ä»£')
    ax1.set_ylabel('å¹³å‡è©•ä¾¡')
    plt.xticks(rotation=45, ha='right')
    st.pyplot(fig1)

    # ã‚°ãƒ©ãƒ•ï¼šæ€§åˆ¥åˆ¥å¹³å‡è©•ä¾¡
    st.subheader("ğŸ“Š æ€§åˆ¥åˆ¥å¹³å‡è©•ä¾¡")
    fig2, ax2 = plt.subplots()
    df.groupby('æ€§åˆ¥')['è©•ä¾¡'].mean().plot.bar(ax=ax2)
    ax2.set_xlabel('æ€§åˆ¥')
    ax2.set_ylabel('å¹³å‡è©•ä¾¡')
    plt.xticks(rotation=0)
    st.pyplot(fig2)

    # ã‚°ãƒ©ãƒ•ï¼šè‚Œè³ªåˆ¥å¹³å‡è©•ä¾¡
    st.subheader("ğŸ“Š è‚Œè³ªåˆ¥å¹³å‡è©•ä¾¡")
    fig3, ax3 = plt.subplots()
    df.groupby('è‚Œè³ª')['è©•ä¾¡'].mean().plot.bar(ax=ax3)
    ax3.set_xlabel('è‚Œè³ª')
    ax3.set_ylabel('å¹³å‡è©•ä¾¡')
    plt.xticks(rotation=45, ha='right')
    st.pyplot(fig3)

    # æ„Ÿæƒ…ã‚¹ã‚³ã‚¢åˆ†å¸ƒ
    st.subheader("ğŸ˜Š æ„Ÿæƒ…ã‚¹ã‚³ã‚¢åˆ†å¸ƒ")
    df['æ„Ÿæƒ…'] = df['æœ¬æ–‡'].apply(lambda x: TextBlob(x).sentiment.polarity)
    fig4, ax4 = plt.subplots()
    df['æ„Ÿæƒ…'].hist(bins=20, ax=ax4)
    ax4.set_xlabel('æ„Ÿæƒ…ã‚¹ã‚³ã‚¢')
    ax4.set_ylabel('ä»¶æ•°')
    st.pyplot(fig4)

    # ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
    st.subheader("ğŸ‘¥ ãƒ¬ãƒ“ãƒ¥ãƒ¼æœ¬æ–‡ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚° (3 clusters)")
    tfidf = TfidfVectorizer(max_features=30)
    X = tfidf.fit_transform(df['æœ¬æ–‡'])
    km = KMeans(n_clusters=3, random_state=42, n_init=10).fit(X)
    df['ã‚¯ãƒ©ã‚¹ã‚¿'] = km.labels_
    st.dataframe(df[['å¹´ä»£','æ€§åˆ¥','è‚Œè³ª','è©•ä¾¡','ã‚¯ãƒ©ã‚¹ã‚¿']])

    # å¹´ä»£Ã—ã‚¯ãƒ©ã‚¹ã‚¿åˆ†å¸ƒ
    st.subheader("ğŸ” å¹´ä»£ Ã— ã‚¯ãƒ©ã‚¹ã‚¿ åˆ†å¸ƒ")
    seg = pd.crosstab(df['å¹´ä»£'], df['ã‚¯ãƒ©ã‚¹ã‚¿'])
    st.dataframe(seg)

    # CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    csv = df.to_csv(index=False).encode('utf-8-sig')
    st.download_button("CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=csv, file_name="cosme_reviews.csv", mime="text/csv")
